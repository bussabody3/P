from pyrogram import Client, filters, enums
from pyrogram.types import Message
from groq import Groq
from config import r, Dev_Zaid
import asyncio

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø¹Ù…ÙŠÙ„ Groq
client_groq = Groq(api_key="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")

@Client.on_message(filters.regex("^Ø¨ÙˆØª (.*)") | filters.command("Ø¨ÙˆØª", ""), group=9988)
async def ai_handler(c: Client, m: Message):
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙØ¹ÙŠÙ„ ÙÙŠ Ø§Ù„Ø®Ø§Øµ Ø£Ùˆ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª
    if m.chat.type != enums.ChatType.PRIVATE and not r.get(f"{m.chat.id}:enable:{Dev_Zaid}"):
        return

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø¤Ø§Ù„
    question = None
    if m.matches:
        question = m.matches[0].group(1)
    elif m.command and len(m.command) > 1:
        question = m.text.split(None, 1)[1]
    
    if not question:
        return

    # Ø¥Ø±Ø³Ø§Ù„ Ø­Ø§Ù„Ø© "ÙŠÙƒØªØ¨"
    await c.send_chat_action(m.chat.id, enums.ChatAction.TYPING)
    
    try:
        # Ø·Ù„Ø¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù† Groq (Ø§Ø³ØªØ®Ø¯Ø§Ù… LLaMA)
        chat_completion = client_groq.chat.completions.create(
            messages=[
                {
                    "role": "user",
                    "content": question,
                }
            ],
            model="llama-3.3-70b-versatile",
        )
        
        response = chat_completion.choices[0].message.content
        await m.reply(f"- Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ LLaMA ğŸ§™:\n\n{response}")
        
    except Exception as e:
        await m.reply(f"âŒ **Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:**\n`{str(e)}`")
